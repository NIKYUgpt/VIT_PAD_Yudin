{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/oli/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['казнить', 'нельзя', ',', 'помиловать', '!?!!']\n",
      "['казнить', 'нельзя', ',', 'помиловать', '!', '?', '!', '!']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = nltk.WordPunctTokenizer()\n",
    "tokens = tokenizer.tokenize('казнить нельзя, помиловать!?!!')\n",
    "print(tokens)\n",
    "\n",
    "tokens = nltk.word_tokenize(\"казнить нельзя, помиловать!?!!\")\n",
    "print(tokens)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "['Это', 'портрет', 'богини', 'Маат', '!', 'Да', '?']"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized = nltk.word_tokenize(\"Это портрет богини Маат! Да?\")\n",
    "tokenized"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Как мы видим, NLTK рассматривает пунктуацию как отдельные токены (что в каких-то случаях может быть полезно). Интересно, что имя с апострофом правильно распозналось как одно слово, а \"it's\" корректно разбилось на два токена."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Стоп-слова\n",
    "Произведём отсечение стоп-слов по словарю."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со']"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('russian')\n",
    "stopwords[:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "[w for w in tokenized if w.lower() not in stopwords]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Лемматизация"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "['волк', 'женщина', 'устранить', 'идти']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymorphy2 # Морфологический анализатор\n",
    "lemm = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "[lemm.parse(w)[0].normal_form for w in ['волки', 'женщины', 'устранено', 'идут']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[[Parse(word='волки', tag=OpencorporaTag('NOUN,anim,masc plur,nomn'), normal_form='волк', score=0.8, methods_stack=((DictionaryAnalyzer(), 'волки', 2, 6),)),\n  Parse(word='волки', tag=OpencorporaTag('NOUN,inan,masc plur,nomn'), normal_form='волк', score=0.1, methods_stack=((DictionaryAnalyzer(), 'волки', 19, 6),)),\n  Parse(word='волки', tag=OpencorporaTag('NOUN,inan,masc plur,accs'), normal_form='волк', score=0.1, methods_stack=((DictionaryAnalyzer(), 'волки', 19, 9),))],\n [Parse(word='женщины', tag=OpencorporaTag('NOUN,anim,femn plur,nomn'), normal_form='женщина', score=0.51269, methods_stack=((DictionaryAnalyzer(), 'женщины', 53, 7),)),\n  Parse(word='женщины', tag=OpencorporaTag('NOUN,anim,femn sing,gent'), normal_form='женщина', score=0.487309, methods_stack=((DictionaryAnalyzer(), 'женщины', 53, 1),))],\n [Parse(word='устранено', tag=OpencorporaTag('PRTS,perf,past,pssv neut,sing'), normal_form='устранить', score=1.0, methods_stack=((DictionaryAnalyzer(), 'устранено', 754, 74),))],\n [Parse(word='идут', tag=OpencorporaTag('VERB,impf,intr plur,3per,pres,indc'), normal_form='идти', score=1.0, methods_stack=((DictionaryAnalyzer(), 'идут', 1696, 6),))]]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lemm.parse(w) for w in ['волки', 'женщины', 'устранено', 'идут']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
